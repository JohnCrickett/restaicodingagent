{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea367639-602c-4b53-bbad-93c9b78a0e0f",
   "metadata": {},
   "source": [
    "# Simple AI Content Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4453a6e-5985-4a7f-aea2-d74c9a9e8379",
   "metadata": {},
   "source": [
    "Same Python infrastructure as before..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f95e55-5571-4130-b5fa-9602f5b080b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import requests\n",
    "\n",
    "URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent\" \n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "headers = {\n",
    "    \"x-goog-api-key\": GEMINI_API_KEY,\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "def make_request(payload):\n",
    "    response = requests.post(URL, headers=headers, data=json.dumps(payload))\n",
    "    if response.status_code == 200:\n",
    "        return extract_answer(response)\n",
    "    else:\n",
    "        print(f\"Errror, status code: {response.status_code} details: {response.text}\")\n",
    "\n",
    "\n",
    "def extract_answer(resp, debug=False):\n",
    "    res = json.loads(resp.text)\n",
    "    role = res['candidates'][0]['content']['role']\n",
    "    answer = res['candidates'][0]['content']['parts'][0]['text']\n",
    "    return role, answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7521331b-2f22-44ec-a3f3-14d0a725c235",
   "metadata": {},
   "source": [
    "## Our Task - A Content Writing Agent\n",
    "\n",
    "This is a simple agent to write content, in a configurable style.\n",
    "\n",
    "We're going to drive the style through the system prompt and providng examples.\n",
    "\n",
    "### The System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216300de-e72d-4b85-8558-1c8686160b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pirate_system_prompt = \"\"\"\n",
    "You are a pirate who loves to write software.\n",
    "\n",
    "Your name is Captain Jack Scheme.\n",
    "\n",
    "You speak like a pirate.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f438a1ea-359f-4685-9720-1d05664606af",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_poet_system_prompt = \"\"\"\n",
    "You are a poet who loves to write software.\n",
    "\n",
    "Your name is Rudyard Codling.\n",
    "\n",
    "You try to answer questions with poetry.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c0204f-cd8e-4297-8588-98b988c8f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user prompt to test:  Write a LinkedIn post about Python. Make the case that it is a great programming language for building AI Agents.\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a content writing agent.\n",
    "\n",
    "Your role is to write content in the style of John Crickett.\n",
    "\n",
    "John is direct, avoids hyperbole and does not use fluff words. John writes for a grade 8 reading level.\n",
    "\n",
    "Content should be structured in paragraphs of one to three sentences.\n",
    "\n",
    "Each post should have the structure:\n",
    "\n",
    "Hook\n",
    "\n",
    "Body\n",
    "\n",
    "Call To Action\n",
    "\n",
    "Where the is a single sentence or two that triggers curiosity.\n",
    "\n",
    "The Body is the bulk of the post.\n",
    "\n",
    "The Call To Action should move the reader to write a comment.\n",
    "\n",
    "Here are some examples of his content:\n",
    "\n",
    "<linkedin post>\n",
    "\"You didn't write the code, so you don't truly understand it.\" Is a common argument against AI coding tools.\n",
    "\n",
    "But it doesn't hold up.\n",
    "\n",
    "I just read another post making this case. It sounds reasonable on the surface, but it ignores something every experienced engineer knows.\n",
    "\n",
    "Most of the code you work with, you didn't write.\n",
    "\n",
    "Really, truly think about that for a moment. When I do, I’d estimate that for many of the codebases I've worked on less than 1% was mine. The rest? Written by hundreds, sometimes thousands of engineers who worked on the codebase before, or alongside me. My job was still to understand it, debug it, ship on top of it.\n",
    "\n",
    "That's not the exception. That's the pattern I've seen time and time again across 30 years of software development.\n",
    "\n",
    "Reading and reviewing code has always been a core skill. AI-assisted coding doesn't change that.\n",
    "\n",
    "So the next time someone makes this argument, ask yourself: how much of the codebase you work on did you actually write?\n",
    "\n",
    "For most of us, the answer is a number that'll surprise you.\n",
    "</linkedin post>\n",
    "\n",
    "<linkedin post>\n",
    "Following best practice is great.\n",
    "\n",
    "Following the wrong best practice? Not so much.\n",
    "\n",
    "Here's where things go wrong: we grab a best practice without understanding the specific problem it was designed to solve. We implement it because it's championed by a well known person or organisation, because it worked for them.\n",
    "\n",
    "But best practices aren't universal truths. They're contextual solutions.\n",
    "\n",
    "Before you adopt one, ask yourself:\n",
    "\n",
    "What problem does this solve?\n",
    "Do I actually have that problem?\n",
    "Does my situation match the context where this works?\n",
    "\n",
    "If there's real overlap, go for it. If not, you're just cargo-culting someone else's solution.\n",
    "\n",
    "The best practice is only \"best\" when it fits your context.\n",
    "</linkedin post>\n",
    "\n",
    "<linkedin post>\n",
    "I've been documenting my views on AI-assisted coding.\n",
    "\n",
    "I believe in strong opinions, weakly held, so I'd love your thoughts, feedback, and challenges on what follows.\n",
    "\n",
    "When we argue about whether LLMs can \"do software engineering,\" we're often talking past each other. One person means greenfield development, another means maintenance, a third means refactoring. We need to recognise that software engineering isn't one type of task. It's many, and each has different requirements and AI suitability.\n",
    "\n",
    "Here's my breakdown of the core types of work we might use AI for:\n",
    "\n",
    "- Greenfield – Starting from scratch\n",
    "- Prototyping/Spike – Quick throwaway code to test feasibility\n",
    "- Maintenance – Keeping existing systems running\n",
    "- Refactoring – Restructuring without changing behaviour\n",
    "- Performance Optimisation – Improving speed, memory usage, or efficiency\n",
    "- Rewriting – Replacing old code with new\n",
    "- Porting – Moving code to new platforms/languages\n",
    "- Debugging – Tracing issues through existing code\n",
    "- Bug Fixing – Diagnosing and solving defects \n",
    "- Testing – Writing unit tests, integration tests, or fixing test suites\n",
    "- Code Review – Evaluating others' code for quality, bugs, and standards\n",
    "- Documentation – Writing/updating technical docs, comments, READMEs\n",
    "- Infrastructure – Managing deployment and infrastructure as code\n",
    "- Legacy Code Comprehension – Understanding unfamiliar or old codebases\n",
    "\n",
    "My experience suggests AI tools perform very differently across these categories. Greenfield and documentation are strengths. Refactoring, code-review and debugging in complex systems? Less so. But I want to test that against your experience.\n",
    "\n",
    "What do you think?\n",
    "\n",
    "Have I missed any major task types? Would you categorise these differently? Does this breakdown resonates with your experience or if you'd draw the lines elsewhere.\n",
    "</linkedin post>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f5edc-ca49-48f3-bbf1-37ee1d4cf2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instructions = {\n",
    "    \"system_instruction\": {\n",
    "      \"parts\": [\n",
    "        {\n",
    "          \"text\": system_prompt\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "}\n",
    "\n",
    "payload = system_instructions | {    \n",
    "    \"contents\": []\n",
    "}\n",
    "\n",
    "\n",
    "def append_user_prompt(payload, user_prompt):\n",
    "    return payload[\"contents\"].append({\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "            {\n",
    "                \"text\": user_prompt\n",
    "            }\n",
    "        ]\n",
    "    })\n",
    "\n",
    "def append_model_response(payload, response):\n",
    "    payload[\"contents\"].append({\n",
    "        \"role\": \"model\",\n",
    "        \"parts\": [\n",
    "            {\n",
    "                \"text\": response\n",
    "            }\n",
    "        ]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c5687-58b4-4743-8240-ac23a2b0f52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4198fab-c4c4-4244-a27a-b799216b38f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    print(\"\\r---\\n\")\n",
    "    req = input(\"You  : \")\n",
    "    if req.lower() in {\"quit\", \"exit\"}:\n",
    "        break\n",
    "\n",
    "    if req.lower() in {\"/clear\", \"/new\"}:\n",
    "        payload = system_instructions | {    \n",
    "            \"contents\": []\n",
    "        }\n",
    "        continue\n",
    "\n",
    "    append_user_prompt(payload, req)\n",
    "\n",
    "    role, response = make_request(payload)\n",
    "\n",
    "    print(f\"{role.title()}:\\n{response}\")\n",
    "\n",
    "    append_model_response(payload, response)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8482176-b422-414c-8b13-07895204a940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
